#!/usr/bin/env python
# coding: utf-8

# # Activity: Explore sampling

# ## Introduction
# In this activity, you will engage in effective sampling of a dataset in order to make it easier to analyze. As a data professional you will often work with extremely large datasets, and utilizing proper sampling techniques helps you improve your efficiency in this work. 

# For this activity, you are a member of an analytics team for the Environmental Protection Agency. You are assigned to analyze data on air quality with respect to carbon monoxide—a major air pollutant—and report your findings. The data utilized in this activity includes information from over 200 sites, identified by their state name, county name, city name, and local site name. You will use effective sampling within this dataset. 

# ## Step 1: Imports

# ### Import packages

# Import `pandas`,  `numpy`, `matplotlib`, `statsmodels`, and `scipy`.


# Import libraries and packages

### YOUR CODE HERE ###
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from scipy import stats



# ### Load the dataset
### YOUR CODE HERE ###
epa_data = pd.read_csv("c4_epa_air_quality.csv", index_col = 0)



# ## Step 2: Data exploration

# ### Examine the data
# 
# To understand how the dataset is structured, examine the first 10 rows of the data.



# First 10 rows of the data

### YOUR CODE HERE ###
epa_data.head(10)



# **Question:** What does the `aqi` column represent?
# It represents the Air Quality Index.

# ### Generate a table of descriptive statistics

# Generate a table of some descriptive statistics about the data. Specify that all columns of the input be included in the output.


### YOUR CODE HERE ###
epa_data.describe(include='all')




# **Question:** Based on the preceding table of descriptive statistics, what is the mean value of the `aqi` column?
# The value is 6.757692.

# **Question:** Based on the preceding table of descriptive statistics, what do you notice about the count value for the `aqi` column?
# The count value for the `aqi` column is 260.


# Now, use the `mean()` function on the `aqi`  column and assign the value to a variable `population_mean`. The value should be the same as the one generated by the `describe()` method in the above table. 

### YOUR CODE HERE ###
population_mean = epa_data['aqi'].mean()
print(population_mean)



# ## Step 3: Statistical tests

# ### Sample with replacement

# First, name a new variable `sampled_data`. Then, use the `sample()` dataframe method to draw 50 samples from `epa_data`. Set `replace` equal to `'True'` to specify sampling with replacement. For `random_state`, choose an arbitrary number for random seed. Make that arbitrary number `42`.

### YOUR CODE HERE ###
sampled_data = epa_data.sample(n=50, replace=True, random_state=42)


# Output the first 10 rows of the DataFrame.
### YOUR CODE HERE ###
sampled_data.head(10)



# **Question:** In the DataFrame output, why is the row index 102 repeated twice?
# Sampling with replacement is random.

# **Question:** What does `random_state` do?
# The parameter lets you create the exact same sample every time, meaning it will pick the same numbers from the dataset each time you use the command.


# ### Compute the mean value from the `aqi` column
# Compute the mean value from the `aqi` column in `sampled_data` and assign the value to the variable `sample_mean`.

### YOUR CODE HERE ###
sample_mean = sampled_data['aqi'].mean()
print(sample_mean)

#  **Question:**  Why is `sample_mean` different from `population_mean`?
# Because samples vary. In this situation, the sample mean is an estimate of the population mean based on a random selection of 50 air quality values, which is smaller than the 260 values in the original dataset.



# ### Apply the central limit theorem
# 
# Imagine repeating the the earlier sample with replacement 10,000 times and obtaining 10,000 point estimates of the mean. In other words, imagine taking 10,000 random samples of 50 AQI values and computing the mean for each sample. According to the **central limit theorem**, the mean of a sampling distribution should be roughly equal to the population mean. Complete the following steps to compute the mean of the sampling distribution with 10,000 samples. 
# 
# * Create an empty list and assign it to a variable called `estimate_list`. 
# * Iterate through a `for` loop 10,000 times. To do this, make sure to utilize the `range()` function to generate a sequence of numbers from 0 to 9,999. 
# * In each iteration of the loop, use the `sample()` function to take a random sample (with replacement) of 50 AQI values from the population. Do not set `random_state` to a value.
# * Use the list `append()` function to add the value of the sample `mean` to each item in the list.


### YOUR CODE HERE ###
estimate_list = []
for i in range(10000):
    estimate_list.append(epa_data['aqi'].sample(n=50,replace=True).mean())



# ### Create a new DataFrame
# 
# Next, create a new DataFrame from the list of 10,000 estimates. Name the new variable `estimate_df`.

### YOUR CODE HERE ###
estimate_df = pd.DataFrame(data={'estimate': estimate_list})
print(estimate_df)



# Next, compute the `mean()` of the sampling distribution of 10,000 random samples and store the result in a new variable `mean_sample_means`.

### YOUR CODE HERE ###
mean_sample_means = estimate_df['estimate'].mean()
print(mean_sample_means)



# **Question:** What is the mean for the sampling distribution of 10,000 random samples?
# This number will vary as `random_state` was not set to a value.



# **Question:** How are the central limit theorem and random sampling (with replacement) related?
# When you randomly pick data from a group, either putting each one back before picking again or not, it's called random sampling with or without replacement.
# This relates to the central limit theorem, which says that if you have a big enough sample and you pick independently, the average of your sample will look like a bell curve.
# In simpler terms, it means that when you take lots of random samples, the average of those samples will tend to be close to the average of the whole group.
# The "mean parameter" is just the average of the whole group, and the "variance parameter" measures how spread out the samples are around that average.



# ### Output the distribution using a histogram

# Output the distribution of these estimates using a histogram. This provides an idea of the sampling distribution.

### YOUR CODE HERE ###
estimate_df['estimate'].hist()




# ### Calculate the standard error

# Calculate the standard error of the mean AQI using the initial sample of 50. The **standard error** of a statistic measures the sample-to-sample variability of the sample statistic. It provides a numerical measure of sampling variability and answers the question: How far is a statistic based on one particular sample from the actual value of the statistic?

### YOUR CODE HERE ###
standard_error = sampled_data['aqi'].std() / np.sqrt(len(sampled_data))
print(standard_error)




# ## Step 4: Results and evaluation

# ###  Visualize the relationship between the sampling and normal distributions

# Visualize the relationship between your sampling distribution of 10,000 estimates and the normal distribution.

# 1. Plot a histogram of the 10,000 sample means 
# 2. Add a vertical line indicating the mean of the first single sample of 50
# 3. Add another vertical line indicating the mean of the means of the 10,000 samples 
# 4. Add a third vertical line indicating the mean of the actual population



### YOUE CODE HERE ###
plt.figure(figsize=(8,5))
plt.hist(estimate_df['estimate'], bins=25, density=True, alpha=0.4, label = "histogram of sample means of 10000 random samples")
xmin, xmax = plt.xlim()
x = np.linspace(xmin, xmax, 100) # generate a grid of 100 values from xmin to xmax.
p = stats.norm.pdf(x, population_mean, standard_error)
plt.plot(x, p, 'k', linewidth=2, label = 'normal curve from central limit theorem')
plt.axvline(x=population_mean, color='m', linestyle = 'solid', label = 'population mean')
plt.axvline(x=sample_mean, color='r', linestyle = '--', label = 'sample mean of the first random sample')
plt.axvline(x=mean_sample_means, color='b', linestyle = ':', label = 'mean of sample means of 10000 random samples')
plt.title("Sampling distribution of sample mean")
plt.xlabel('sample mean')
plt.ylabel('density')
plt.legend(bbox_to_anchor=(1.04,1));


# **Question:** What insights did you gain from the preceding sampling distribution?
# The histogram of the sampling distribution looks like a bell curve, as predicted by the central limit theorem.
# When we look at just one sample, it might not match the true average. This is normal because samples can vary.
# The average of all the sample averages (blue dotted line) and the average of the whole population (green solid line) are very close to each other, showing that our method of estimating the average works well.

# # Considerations
# 
# **What are some key takeaways that you learned from this lab?**
# Sampling with replacement can create duplicate rows in a dataset, while differences between sample and population means arise from sampling variability.
# The central limit theorem aids in understanding the distribution of sample means across various datasets.

# **What findings would you share with others?**
# In a sample of 50 observations, the average AQI was below 100, indicating satisfactory air quality. Further analysis is needed to explore AQI values outside this range, particularly those indicating unhealthy air quality.

# **What would you convey to external stakeholders?**
# I would communicate to external stakeholders that, overall, carbon monoxide levels are satisfactory.
# However, it's essential to direct funding towards investigating areas with unhealthy levels of carbon monoxide and implementing measures to improve air quality in those regions.


# **Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the "save" icon at the top of this notebook to ensure your work has been logged.
